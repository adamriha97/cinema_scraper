name: Github Actions Crawl

on:
    workflow_dispatch:
    schedule:
        - cron:  '15 1 * * 0,1,3,4,5,6'
        - cron:  '15 1 * * 2'

jobs:
    spider:
        runs-on: ubuntu-latest
        
        strategy:
            matrix:
                python-version: ['3.10']
        
        env:
            SCRAPEOPS_API_KEY: ${{ secrets.SCRAPEOPS_API_KEY }}
            MONGODB_URI: ${{ secrets.MONGODB_URI }}
            MONGODB_DATABASE: ${{ secrets.MONGODB_DATABASE }}

        steps:
            - uses: actions/checkout@v3

            - name: Set up Python
              uses: actions/setup-python@v4
              with:
                python-version: ${{ matrix.python-version }}
            
            - name: Install dependencies
              run: |
                python -m pip install --upgrade pip
                pip install -r requirements.txt
                cp -v mid_for_scr_sel.py /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/scrapy_selenium/middlewares.py

            - name: Run spider
              run: |
                cd cinema_scraper_project
                scrapy crawl csfd_program_spider
                scrapy crawl csfd_premiere_spider
            
            - name: Run spider Tuesday
              if: github.event.schedule != '15 1 * * 0,1,3,4,5,6'
              run: |
                cd cinema_scraper_project
                scrapy crawl cinestar_program_spider
                scrapy crawl cinemacity_program_spider
                scrapy crawl aero_program_spider
